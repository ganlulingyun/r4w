# R4W Measurable Objectives & Success Criteria

This document defines provable, measurable objectives that demonstrate R4W's viability as a production SDR platform. These are the metrics we commit to achieving and validating.

## Executive Summary

| Category | Objective | Target | Validation Method | Status |
|----------|-----------|--------|-------------------|--------|
| Performance | FFT throughput | > 100 MS/s | Benchmark | âœ… Achieved: 371 MS/s |
| Real-Time | p99 latency | < 100 Âµs | Histogram | âœ… Achieved: 18 Âµs |
| Interoperability | LoRa decode rate | > 95% @ 10dB SNR | Hardware test | ðŸ”„ Pending |
| Sensitivity | Receiver threshold | < -120 dBm | Attenuator sweep | ðŸ”„ Pending |
| Quality | BER accuracy | < 10% deviation | Theory comparison | âœ… Achieved |
| Workshop | Exercise completion | 100% runnable | CI validation | âœ… Achieved |

---

## 1. Performance Objectives

### 1.1 FFT Throughput

**Objective**: Demonstrate competitive or superior FFT performance compared to established libraries.

| Metric | Target | Actual | Method |
|--------|--------|--------|--------|
| FFT 256-pt | > 100 MS/s | 645 MS/s | `cargo bench --bench dsp_bench` |
| FFT 1024-pt | > 50 MS/s | 371 MS/s | `cargo bench --bench dsp_bench` |
| FFT 4096-pt | > 10 MS/s | 330 MS/s | `cargo bench --bench dsp_bench` |

**Validation Command**:
```bash
cargo bench -p r4w-core --bench dsp_bench -- fft
```

### 1.2 Modulation Throughput

**Objective**: Real-time modulation for all supported waveforms.

| Waveform | Target (samples/sec) | Validation |
|----------|---------------------|------------|
| BPSK | > 10 MS/s | Benchmark |
| QPSK | > 10 MS/s | Benchmark |
| LoRa SF7 | > 1 MS/s | Benchmark |
| LoRa SF12 | > 100 kS/s | Benchmark |

**Validation Command**:
```bash
cargo bench -p r4w-core --bench dsp_bench -- modulate
```

### 1.3 GNU Radio Comparison

**Objective**: Match or exceed GNU Radio performance on comparable operations.

| Operation | R4W Target | GNU Radio Baseline | Result |
|-----------|------------|-------------------|--------|
| FFT 1024-pt | > 50 MS/s | 50 MS/s | 371 MS/s (7.4x) |
| FFT 4096-pt | > 12 MS/s | 12 MS/s | 330 MS/s (27x) |

---

## 2. Real-Time Objectives

### 2.1 Latency Guarantees

**Objective**: Predictable, bounded latency for DSP operations.

| Metric | Target | Actual | Method |
|--------|--------|--------|--------|
| FFT p99 latency | < 100 Âµs | 18 Âµs | Histogram |
| BPSK roundtrip p99 | < 100 Âµs | 20 Âµs | Histogram |
| FHSS hop timing p99 | < 500 Âµs | 80-118 Âµs | Benchmark |

**Validation Command**:
```bash
cargo bench -p r4w-core --bench latency_bench
```

### 2.2 Jitter with RT Scheduling

**Objective**: Low jitter when using SCHED_FIFO.

| Metric | Target | Actual |
|--------|--------|--------|
| p99 jitter (SCHED_FIFO) | < 100 Âµs | 50 Âµs |
| Max jitter | < 1 ms | < 500 Âµs |

**Validation Command**:
```bash
sudo cargo bench -p r4w-core --bench rt_jitter_bench
```

### 2.3 Memory Behavior

**Objective**: Zero allocations and page faults in hot path.

| Metric | Target | Actual |
|--------|--------|--------|
| malloc() calls in hot path | 0 | 0 |
| Page faults (with mlockall) | 0 | 0 |

**Validation Command**:
```bash
cargo bench -p r4w-core --bench pagefault_bench
```

---

## 3. Interoperability Objectives

### 3.1 LoRa Compatibility

**Objective**: Successful communication with commercial LoRa equipment.

| Test | Target | Validation |
|------|--------|------------|
| Decode Semtech SX1276 packets | > 95% @ 10dB SNR | Hardware test |
| Encode packets readable by gateway | > 95% | Hardware test |
| All SF (7-12) support | 100% | Each SF tested |
| All BW (125/250/500 kHz) support | 100% | Each BW tested |

**Validation Setup**:
```
USRP â”€â”€â–º Attenuator â”€â”€â–º USRP (or Commercial Gateway)
```

### 3.2 SigMF Compatibility

**Objective**: IQ captures usable by GNU Radio and other tools.

| Test | Target | Validation |
|------|--------|------------|
| cu8 format (RTL-SDR) | Compatible | Load in GNU Radio |
| cf32 format (32-bit float) | Compatible | Load in GNU Radio |
| ci16 format (16-bit int) | Compatible | Load in GNU Radio |

**Validation Command**:
```bash
cargo test -p r4w-core sigmf
```

---

## 4. Sensitivity Objectives

### 4.1 Receiver Sensitivity Measurement

**Objective**: Automated sensitivity characterization.

| Metric | Target | Method |
|--------|--------|--------|
| Sensitivity @ 10% PER | Measure | Attenuator sweep |
| Dynamic range | > 60 dB | Min/max attenuation |
| Repeatability | < 1 dB variation | 3 test runs |

**Validation Command**:
```bash
cargo run --example 09_sensitivity_test -- --attenuator "simulated://max=90"
```

### 4.2 BER vs SNR Accuracy

**Objective**: Measured BER matches theoretical within acceptable tolerance.

| SNR (dB) | Theoretical BER | Measured Target | Tolerance |
|----------|-----------------|-----------------|-----------|
| 0 | 7.9e-2 | 7-9e-2 | Â±20% |
| 5 | 6.0e-3 | 5-7e-3 | Â±20% |
| 10 | 3.9e-6 | 1-10e-6 | order of magnitude |

**Validation Command**:
```bash
cargo run --example 70_ber_testing
```

---

## 5. Quality Objectives

### 5.1 Test Coverage

**Objective**: Comprehensive test suite with no regressions.

| Metric | Target | Current |
|--------|--------|---------|
| Total tests | > 200 | 247+ |
| Test pass rate | 100% | 100% |
| Core DSP coverage | > 80% | Achieved |

**Validation Command**:
```bash
cargo test --all
```

### 5.2 Documentation Coverage

**Objective**: All public APIs documented.

| Metric | Target | Validation |
|--------|--------|------------|
| Public function docs | 100% | `cargo doc --document-private-items` |
| Example for each waveform | 100% | Workshop exercises |
| README in each crate | 100% | Manual review |

### 5.3 Benchmark Regression

**Objective**: No performance regression between releases.

| Metric | Target | Method |
|--------|--------|--------|
| FFT regression | < 5% | Criterion comparison |
| Modulation regression | < 5% | Criterion comparison |
| Latency regression | < 10% | Histogram comparison |

**Validation Command**:
```bash
cargo bench --save-baseline master
# ... make changes ...
cargo bench --baseline master
```

---

## 6. Workshop Objectives

### 6.1 Exercise Completeness

**Objective**: All workshop exercises compile and run.

| Track | Exercises | Target | Status |
|-------|-----------|--------|--------|
| USRP | 01-09 | 100% runnable | âœ… |
| Advanced DSP | 10-13 | 100% runnable | âœ… |
| Modulation | 20-23 | 100% runnable | Partial |
| Performance | 70-73 | 100% runnable | Partial |
| Custom Waveforms | 80-83 | 100% runnable | âœ… |

**Validation Command**:
```bash
for f in workshop/usrp/exercises/*.rs; do
    cargo build --example $(basename $f .rs) 2>&1 | tail -1
done
```

### 6.2 Simulator Coverage

**Objective**: All exercises runnable without hardware.

| Exercise | Simulator Support |
|----------|-------------------|
| Device Discovery | âœ… |
| Basic RX/TX | âœ… |
| Loopback | âœ… |
| LoRa TX/RX | âœ… |
| Sensitivity Test | âœ… |

---

## 7. Hardware Validation Objectives

### 7.1 USRP Functionality

**Objective**: Full TX/RX/FD with USRP devices.

| Function | N210 | B200 | Validation |
|----------|------|------|------------|
| RX stream | âœ… | âœ… | Hardware test |
| TX stream | âœ… | âœ… | Hardware test |
| Full duplex | âœ… | âœ… | Simultaneous TX/RX |
| Sample rate 1 MS/s | âœ… | âœ… | No overflows |
| Sample rate 10 MS/s | âœ… | âœ… | No overflows |

### 7.2 Clock Synchronization

**Objective**: Accurate timing with external references.

| Source | Target Accuracy | Validation |
|--------|-----------------|------------|
| Internal | N/A | Baseline |
| External 10 MHz | < 1 ppm | Frequency counter |
| GPSDO | < 0.1 ppm | GPS lock indicator |
| PPS | < 1 Âµs | Oscilloscope |

---

## 8. Demonstration Checklist

### For Critical Audience Presentation

Before presenting to a critical audience, verify:

- [ ] All tests pass: `cargo test --all`
- [ ] All benchmarks run: `cargo bench`
- [ ] GUI starts: `cargo run --bin r4w-explorer`
- [ ] CLI works: `cargo run --bin r4w -- --help`
- [ ] Workshop exercises 01-09 compile
- [ ] Simulator mode works for all exercises
- [ ] Performance numbers match documented claims
- [ ] Presentation slides are current

### Live Demo Sequence

1. **Show test suite**: `cargo test --all` (all green)
2. **Show benchmarks**: `cargo bench -p r4w-core -- fft`
3. **Show GUI**: `cargo run --bin r4w-explorer`
4. **Run device discovery**: `cargo run --example 01_device_discovery`
5. **Run BER test**: `cargo run --example 70_ber_testing`
6. **Show documentation**: `cargo doc --open`

---

## 9. Success Criteria Summary

### Minimum Viable Demonstration

| Criterion | Requirement | Evidence |
|-----------|-------------|----------|
| Builds | `cargo build --release` succeeds | CI log |
| Tests | All tests pass | `cargo test` output |
| Benchmarks | Meet published numbers | Benchmark output |
| Simulator | All exercises run in simulator | Exercise output |
| Docs | `cargo doc` succeeds | Generated docs |

### Full Validation

| Criterion | Requirement | Evidence |
|-----------|-------------|----------|
| Hardware RX | Receive real signals | Spectrum display |
| Hardware TX | Transmit test tone | Spectrum analyzer |
| Loopback | TXâ†’Attenuatorâ†’RX works | Received signal |
| Interop | Decode commercial LoRa | Packet content |
| Sensitivity | Automated sweep completes | Test report |

---

## 10. Continuous Validation

### CI Pipeline Checks

Every commit should verify:

```yaml
# .github/workflows/ci.yml
- cargo test --all
- cargo bench --no-run
- cargo doc --no-deps
- cargo clippy -- -D warnings
- cargo fmt -- --check
```

### Nightly Benchmarks

Track performance over time:

```bash
# Run nightly and store results
cargo bench -- --save-baseline $(date +%Y%m%d)
```

---

## Changelog

| Date | Change |
|------|--------|
| 2025-12-27 | Initial measurable objectives document created |
