name: Benchmarks

on:
  push:
    branches: [main, master]
  pull_request:
    branches: [main, master]

env:
  CARGO_TERM_COLOR: always

permissions:
  contents: write
  pull-requests: write

jobs:
  benchmark:
    name: Performance Regression Check
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Install Rust
        uses: dtolnay/rust-toolchain@stable

      - name: Cache cargo registry
        uses: actions/cache@v4
        with:
          path: |
            ~/.cargo/registry
            ~/.cargo/git
            target
          key: ${{ runner.os }}-cargo-bench-${{ hashFiles('**/Cargo.lock') }}
          restore-keys: |
            ${{ runner.os }}-cargo-bench-

      - name: Run benchmarks
        run: |
          # Run benchmarks and capture output
          cargo bench --package r4w-core -- --noplot 2>&1 | tee benchmark_output.txt

          # Generate JSON output for github-action-benchmark
          # Parse criterion output and create compatible format
          echo '[]' > benchmark_results.json

          # Extract benchmark results and create JSON
          python3 << 'EOF'
          import re
          import json
          import sys

          results = []
          current_bench = None

          with open('benchmark_output.txt', 'r') as f:
              for line in f:
                  # Match benchmark name lines like "bench_name  time:   [1.234 µs 1.250 µs 1.267 µs]"
                  match = re.match(r'^(\S+)\s+time:\s+\[([^\]]+)\]', line.strip())
                  if match:
                      bench_name = match.group(1)
                      times = match.group(2).split()
                      # Parse median time (middle value)
                      if len(times) >= 3:
                          median_str = times[1]
                          # Parse time value and unit
                          time_match = re.match(r'([\d.]+)\s*(\w+)', median_str)
                          if time_match:
                              value = float(time_match.group(1))
                              unit = time_match.group(2)
                              # Convert to nanoseconds for consistency
                              multipliers = {'ns': 1, 'µs': 1000, 'us': 1000, 'ms': 1000000, 's': 1000000000}
                              if unit in multipliers:
                                  value_ns = value * multipliers[unit]
                                  results.append({
                                      'name': bench_name,
                                      'unit': 'ns',
                                      'value': value_ns
                                  })

          with open('benchmark_results.json', 'w') as f:
              json.dump(results, f, indent=2)

          print(f"Parsed {len(results)} benchmark results")
          EOF

      - name: Extract benchmark results
        id: bench
        run: |
          # Parse criterion output for key metrics
          echo "## Benchmark Results" > benchmark_summary.md
          echo "" >> benchmark_summary.md
          echo "| Benchmark | Time |" >> benchmark_summary.md
          echo "|-----------|------|" >> benchmark_summary.md

          # Extract timing from criterion output
          grep -E "time:.*\[" benchmark_output.txt | while read line; do
            bench_name=$(echo "$line" | sed 's/time:.*//' | xargs)
            time=$(echo "$line" | grep -oE '\[[^]]+\]' | head -1)
            echo "| $bench_name | $time |" >> benchmark_summary.md
          done

          cat benchmark_summary.md

          # Check if we have benchmark results
          if [ -s benchmark_results.json ] && [ "$(cat benchmark_results.json)" != "[]" ]; then
            echo "has_results=true" >> $GITHUB_OUTPUT
          else
            echo "has_results=false" >> $GITHUB_OUTPUT
          fi

      - name: Store benchmark result
        uses: benchmark-action/github-action-benchmark@v1
        if: github.event_name == 'push' && steps.bench.outputs.has_results == 'true'
        with:
          name: R4W Benchmarks
          tool: 'customSmallerIsBetter'
          output-file-path: benchmark_results.json
          github-token: ${{ secrets.GITHUB_TOKEN }}
          auto-push: true
          alert-threshold: '150%'
          comment-on-alert: true
          fail-on-alert: false
          alert-comment-cc-users: '@${{ github.repository_owner }}'

      - name: Compare PR benchmarks
        if: github.event_name == 'pull_request' && steps.bench.outputs.has_results == 'true'
        uses: benchmark-action/github-action-benchmark@v1
        with:
          name: R4W Benchmarks
          tool: 'customSmallerIsBetter'
          output-file-path: benchmark_results.json
          github-token: ${{ secrets.GITHUB_TOKEN }}
          auto-push: false
          alert-threshold: '130%'
          comment-on-alert: true
          fail-on-alert: true
          alert-comment-cc-users: '@${{ github.actor }}'

      - name: Comment on PR with results
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const summary = fs.readFileSync('benchmark_summary.md', 'utf8');

            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: summary
            });
